{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratorio 1 - Parte 2\n",
    "\n",
    "### Regresión logística y Funciones Discriminantes Gausianas\n",
    "\n",
    "### 2020 - II\n",
    "\n",
    "#### Profesor: Julián D. Arias Londoño\n",
    "#### julian.ariasl@udea.edu.co\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En este archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: No olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "#Algunas advertencias que queremos evitar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer integrante:\n",
    "Nombre:\n",
    "\n",
    "\n",
    "#### Segundo integrante:\n",
    "\n",
    "Nombre:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Contextualización del problema\n",
    "\n",
    "El problema de *clasificación* que están cargados en el archivo `DatosClases.mat`. Las variables o caracterísicas son guardadas en  X y la variable de salida es guardada en la variable Y. \n",
    "\n",
    "Responda las siguientes preguntas y grafique los datos usando la funci&oacute;n [scatter](https://matplotlib.org/gallery/shapes_and_collections/scatter.html) de matplotlib y responda las siguientes preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('DB/DatosClases.mat')\n",
    "X = mat['X'] # Matriz X de muestras con las características\n",
    "Y = mat['Y'] # Variable de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 ¿Cu&aacute;ntas clases tiene el problema?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 ¿Cu&aacute;ntas caracter&iacute;sticas tiene el problema?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 ¿Cu&aacute;ntas muestras tiene el problema?:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Gráfica del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 ¿El problema es linealmente separable?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Completar código\n",
    "\n",
    "En este laboratorio se va a realizar un procedimiento análogo al laboratorio anterior, pero con el modelo de *regresión logística* que sirve para resolver problemas de clasificación (en principio biclase).\n",
    "\n",
    "Analice los siguientes métodos a la luz de la teoría vista para el modelo de regresión logística, tales como la función de activación (<font color='blue'>sigmoidal</font>), el modelo de regresión logística (<font color='blue'>logistic_regression</font>), potencia del polinomio y el cálculo del error en clasificación (<font color='blue'>error_logistic</font>) y el gradiente descendente. \n",
    "\n",
    "Una vez comprenda su funcionamiento proceda a realizar lo siguiente:\n",
    "\n",
    "1. Completar el código del método de <font color='blue'>gradiente_descedente_logistic</font> con la regla de actualización de los parámetros para el problema de clasificación\n",
    "\n",
    "$$w_j(iter) = w_j(iter-1) - \\eta \\frac{\\partial E(w)}{\\partial w_j}$$ \n",
    "\n",
    "Nota: Para el problema de clasificación tenga presente que si ya implementó la regla de actualización de parámetros para el modelo de regresión polinomial múltiple, este punto es trivial, puesto que sólo tiene que incluir la función sigmoidal tal como lo vimos en la teoría.\n",
    "\n",
    "2. Graficar el error de clasificación durante las iteraciones del algoritmo. La gráfica debe llevar título y los correspondientes nombres de los ejes.\n",
    "\n",
    "Nota: Observe que el método logistic_regression ya hace el llamado a la función sigmoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de activación Sigmoidal\n",
    "def sigmoidal(z):\n",
    "    \n",
    "    #Complete la siguiente línea con el código para calcular la salida de la función sigmoidal\n",
    "    s = \n",
    "    \n",
    "    \n",
    "    return s\n",
    "\n",
    "\n",
    "#Modelo Regresión logística\n",
    "def logistic_regression(X, W):\n",
    "    #Con np.dot se realiza el producto matricial. Aquí X (extendida) tiene dim [Nxd] y W es dim [dx1]\n",
    "    Yest = np.dot(X,W)\n",
    "    \n",
    "    Y_lest = sigmoidal(Yest)\n",
    "    \n",
    "    #Se asignan los valores a 1 o 0 según el modelo de regresión logística definido\n",
    "    pos = 0\n",
    "    for tag in Y_lest:\n",
    "        \n",
    "        if tag > 0.5:\n",
    "            Y_lest[pos] = 1\n",
    "        elif tag < 0.5:\n",
    "            Y_lest[pos] = 0\n",
    "        \n",
    "        pos += 1\n",
    "    \n",
    "    return Y_lest    #Y estimado: Esta variable contiene ya tiene la salida de sigm(f(X,W))\n",
    "\n",
    "\n",
    "#En este laboratorio solo trabajaremos el caso lineal (grado 1), pero se pueden probar otras fronteras\n",
    "def potenciaPolinomio(X,grado):\n",
    "    X2 = X\n",
    "    \n",
    "    if grado != 1:\n",
    "        for i in range(2,grado+1):\n",
    "            Xadd = X**i\n",
    "            X2 = np.concatenate((X2, Xadd), axis=1)\n",
    "    \n",
    "    return X2\n",
    "\n",
    "\"\"\"\n",
    "Calcular el error del modelo de regresión logístic\n",
    "Si es diferente el Y_estimado con el Y_real cuenta como un error\n",
    "Y_lest: Y estimado del algoritmo\n",
    "Y: Y real de los datos\n",
    "\n",
    "\"\"\"\n",
    "def error_logistic(Y_lest, Y):\n",
    "    error = 0\n",
    "    for ye, y in zip(Y_lest, Y):\n",
    "        if ye != y:\n",
    "            error += 1\n",
    "    \n",
    "    error = error/np.size(Y)\n",
    "    \n",
    "    #print (\"La eficiencia en esta iteración fue: \"+str(1-error)+'\\n')\n",
    "    \n",
    "    return error\n",
    "\n",
    "\"\"\"Gradiente descendente para regresión lineal múltiple\n",
    "X: Matriz de datos extendida.\n",
    "W: Vector de parámetros del modelo\n",
    "eta: Taza de aprendizaje\n",
    "\"\"\"\n",
    "def gradiente_descendente_logistic(X,Y,grado,eta, graph=False):\n",
    "    \n",
    "    #Extendemos la matriz\n",
    "    unos = np.array([np.ones(np.size(X,0))]\n",
    "                   )\n",
    "    #Concatenar el vector de unos con la matriz X\n",
    "    X = np.concatenate((unos.T, X), axis=1)\n",
    "    X = X.reshape(np.size(X,0),np.size(X,1))\n",
    "    \n",
    "    Y = Y.reshape(np.size(Y), 1)\n",
    "    \n",
    "    #Tomamos el número de variables del problema\n",
    "    d = np.size(X,1)\n",
    "\n",
    "    #Tomamos el número de muestras de la base de datos\n",
    "    N = np.size(X,0)\n",
    "    \n",
    "    #Inicializamos el vector de parámetros \n",
    "    W = np.zeros(d)\n",
    "    W = W.reshape(np.size(W),1)\n",
    "\n",
    "    eta = eta\n",
    "    \n",
    "    iteraciones = 1000\n",
    "    errores = np.zeros(iteraciones)\n",
    "    \n",
    "    for iter in range(iteraciones):\n",
    "\n",
    "        Y_estimado = logistic_regression(X,W)\n",
    "        #Error en clasificación\n",
    "        error = error_logistic(Y_estimado,Y)\n",
    "        errores[iter] = error\n",
    "\n",
    "        #Aquí debe completar el código con la regla de actualización de los parámetros W para regresión\n",
    "        #logística. Tenga en cuenta los nombres de las variables ya creadas: W, X, Y\n",
    "        \n",
    "    \n",
    "    if graph:\n",
    "  \n",
    "        #Aquí debe completar el código para realizar la gráfica del error de clasificación vs. iteraciones\n",
    "    \n",
    "    \n",
    "    print ('Vector de parámetros del modelo:\\n')\n",
    "    print (W)\n",
    "    print ('\\nError de entrenamiento = ' + str(errores[-1]))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Entrenamiento\n",
    "\n",
    "1. Complete el código de la siguiente celda llamando el método <font color='blue'>gradiente_descedente_logistic</font>, se debe pasar los parámetros que corresponde con la tabla de resultados de abajo\n",
    "2. Ejecute el entrenamiento\n",
    "3. Llene la tabla de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "import math\n",
    "N = np.size(X,0)\n",
    "\n",
    "# #Se modifica la matriz de datos original de acuerdo al grado del polinomio ingresado para el modelo\n",
    "grado = \n",
    "X2 = potenciaPolinomio(X,grado)\n",
    "\n",
    "#Dejamos algunas muestras para el proceso de entrenamiento y otras para evaluar qué tan bueno fue el aprendizaje del modelo\n",
    "random.seed(1)\n",
    "ind=np.random.permutation(N)\n",
    "Xtrain = X2[ind[0:int(math.ceil(0.7*N))],:]\n",
    "Xtest = X2[ind[int(math.ceil(0.7*N)):N],:]\n",
    "Ytrain = Y[ind[0:int(math.ceil(0.7*N))]]\n",
    "Ytest = Y[ind[int(math.ceil(0.7*N)):N]]\n",
    "\n",
    "#Normalizamos los datos\n",
    "media = np.mean(Xtrain)\n",
    "desvia = np.std(Xtrain)\n",
    "Xtrain = stats.stats.zscore(Xtrain)\n",
    "Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n",
    "\n",
    "eta = \n",
    "\n",
    "#Complete la siguiente línea de código llamando el método gradiente_descendente con sus respectivos argumentos\n",
    "W = \n",
    "\n",
    "#Evaluamos las predicciones del modelo con los datos de test\n",
    "unos = np.array([np.ones(np.size(Xtest,0))])\n",
    "Xtest2 = np.concatenate((unos.T, Xtest), axis=1)\n",
    "Xtest2 = Xtest2.reshape(np.size(Xtest2,0),np.size(Xtest2,1))\n",
    "Yest = logistic_regression(Xtest2, W)\n",
    "Error = error_logistic(Yest,Ytest)\n",
    "print('\\nError durante la prueba = ' + str(Error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabla de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7453e46e7e0a4a13a0db8c3cf5b7c320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import qgrid\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'Tasa de aprendizaje' : pd.Series(['1', '1', '1', '1', '1', '0.1', '0.1', '0.1', '0.1', '0.1', '0.001', '0.001', '0.001', '0.001', '0.001']),\n",
    "    'Grado del polinomio' : pd.Series([1,2,3,4,5,1,2,3,4,5,1,2,3,4,5])})\n",
    "df_types[\"Error_Entrenamiento\"] = \"\"\n",
    "df_types[\"Error_Prueba\"] = \"\"\n",
    "df_types.set_index(['Tasa de aprendizaje','Grado del polinomio'], inplace=True)\n",
    "df_types[\"Error_Entrenamiento\"][2] = \"0.0\"\n",
    "df_types[\"Error_Prueba\"][2] = \"0.5\"\n",
    "df_types.sort_index(inplace=True)\n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute la siguiente instrucción para dejar guardados en el notebook los resultados de las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Error_Entrenamiento</th>\n",
       "      <th>Error_Prueba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tasa de aprendizaje</th>\n",
       "      <th>Grado del polinomio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.001</th>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.1</th>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Error_Entrenamiento Error_Prueba\n",
       "Tasa de aprendizaje Grado del polinomio                                 \n",
       "0.001               1                                                   \n",
       "                    2                                                   \n",
       "                    3                                                   \n",
       "                    4                                                   \n",
       "                    5                                                   \n",
       "0.1                 1                                                   \n",
       "                    2                                                   \n",
       "                    3                                                   \n",
       "                    4                                                   \n",
       "                    5                                                   \n",
       "1                   1                                                   \n",
       "                    2                                                   \n",
       "                    3                                   0.0          0.5\n",
       "                    4                                                   \n",
       "                    5                                                   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "4.1 Escriba el modelo completo con sus variables y coeficientes de $f(\\textbf{x},\\textbf{w})$ con la mejor frontera de decisión que encontró según la tabla de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Basado en el valor del error obtenido, ¿cu&aacute;ntas muestras de entrenamiento y de prueba clasifica mal el modelo? (un valor para el conjunto de entrenamiento y pruebas). Nota. Escriba en una celda el código con el cuál obtuvo la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código utiliza un clasificador basado en Funciones Discriminantes Gaussianas para resolver el mismo problema de clasificación. Ejecute el código y responda las siguientes preguntas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistribucionGaussiana(X,Mu,Sigma):\n",
    "    \n",
    "    SigmaInversa = np.linalg.inv(np.array(Sigma))\n",
    "    PrimerTermino = (1/(2*math.pi*math.sqrt(np.linalg.det(Sigma))))\n",
    "    \n",
    "    primerDot = np.dot((X-Mu),SigmaInversa)\n",
    "    segundoDot = np.dot(primerDot,(X-Mu).T)\n",
    "    Exponencial = math.exp(-0.5*segundoDot)\n",
    "    \n",
    "    Probabilidad = PrimerTermino * Exponencial\n",
    "    \n",
    "    return Probabilidad\n",
    "\n",
    "def FuncionDiscriminanteG(Xtrain,Ytrain,Xtest,tipo):\n",
    "    \n",
    "    N = Xtest.shape[0]\n",
    "    #Estimación de medias y Covarianzas\n",
    "    Mu1 = np.mean(Xtrain[(Ytrain==1).flat,:], axis=0)\n",
    "    Mu2 = np.mean(Xtrain[(Ytrain==0).flat,:], axis=0)\n",
    "  \n",
    "    Sigma1 = np.cov((Xtrain[(Ytrain==1).flat,:]).T)\n",
    "    Sigma2 = np.cov((Xtrain[(Ytrain==0).flat,:]).T)\n",
    "    \n",
    "    Sigma3 = (0.5*(Sigma1+Sigma2))\n",
    "    Yest = np.zeros(N)\n",
    "    Tipo = tipo\n",
    "    for i in range(N):\n",
    "        \n",
    "            if Tipo == 0 :\n",
    "                p1 = DistribucionGaussiana(Xtest[i,:],Mu1,Sigma1)\n",
    "                p2 = DistribucionGaussiana(Xtest[i,:],Mu2,Sigma2)\n",
    "            elif Tipo == 1:\n",
    "                p1 = DistribucionGaussiana(Xtest[i,:],Mu1,Sigma3)\n",
    "                p2 = DistribucionGaussiana(Xtest[i,:],Mu2,Sigma3)\n",
    "            if p1 >= p2:\n",
    "                Yest[i] = 1\n",
    "            else:\n",
    "                Yest[i] = 0\n",
    "                \n",
    "    return Yest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo = 0 # Frontera lineal\n",
    "Yest0 = FuncionDiscriminanteG(Xtrain,Ytrain,Xtest,tipo)\n",
    "Error = error_logistic(Yest0,Ytest)\n",
    "print('\\nError prueba (Frontera Lineal) = ' + str(Error))\n",
    "\n",
    "\n",
    "tipo = 1 #Frontera cuadrática\n",
    "Yest1 = FuncionDiscriminanteG(Xtrain,Ytrain,Xtest,tipo)\n",
    "Error = error_logistic(Yest1,Ytest)\n",
    "print('\\nError prueba (Frontera cuadrática) = ' + str(Error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 ¿Cuál tipo de frontera proporcionó mejores resultados?:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Teniendo en cuenta la forma de los datos (De acuerdo con la gráfica hecha en el punto 2), expliqué porqué el modelo de Funciones Discriminantes Gaussianas obtiene un buen resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
